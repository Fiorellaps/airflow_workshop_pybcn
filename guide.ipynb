{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97860e10-a081-46ef-b70b-50aa80f75ff7",
   "metadata": {},
   "source": [
    "# Workshop de Airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec09b36d-fc61-4184-8ad9-9f0cb88da334",
   "metadata": {},
   "source": [
    "# 1. Instalación de Airflow en Linux"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6f8996-13e4-43c9-91e1-f67d7194886e",
   "metadata": {},
   "source": [
    "- Creamos un entorno de Python con virtualenv y lo activamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006fca2d-46fb-4702-8aaf-ed7087b07a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m venv airflow_env\n",
    ">source airflow_env/bin/ativate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c419f423-6cda-44b0-9e39-9fafb969ee9a",
   "metadata": {},
   "source": [
    "- Definimos **AIRFLOW_HOME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3be0424-27d0-43a5-a64a-1b2eafd5f687",
   "metadata": {},
   "outputs": [],
   "source": [
    ">export AIRFLOW_HOME=~/airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb7025-bd37-4b20-bf30-68cf635711d3",
   "metadata": {},
   "source": [
    "- Instalamos airflow desde Pypi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8588c0d2-0380-41f5-9831-514b53362bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install \"apache-airflow[gcp]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0416ea34-b79b-4633-b953-463196a0e1b4",
   "metadata": {},
   "source": [
    "<div style=\"color:green\">Airflow ofrece muchos más <a href=\"https://airflow.apache.org/docs/#providers-packagesdocsapache-airflow-providersindexhtml\">providers</a>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c3f97-e32d-4505-976e-50e8c8fdb54b",
   "metadata": {},
   "source": [
    "- Modificar la configuración de airflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187cdc54-5977-49d1-be3d-4eb4ce33309e",
   "metadata": {},
   "outputs": [],
   "source": [
    ">nano /root/airflow/airflow.cfg\n",
    "#- load_examples=False\n",
    "#- sql_alchemy_conn = postgresql+psycopg2://user:pass@localhost:5432/airflow_db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc96c08-7a74-4daf-b113-054f5d0fcfc2",
   "metadata": {},
   "source": [
    "- Comprobamos que está bien instalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cc64f9-b72c-4e8c-8168-5f4b8ebc7079",
   "metadata": {},
   "outputs": [],
   "source": [
    "airflow version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9c2d7f-1bb9-42b0-a9b6-25c74000e063",
   "metadata": {},
   "source": [
    "- Arrancamos airflow manualmente\n",
    "<div style=\"color:green\">** También se podría arrancar usando el comando `airflow standalone` o en modo cluster\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53704954-35b0-495f-8306-52fb3e53d0e6",
   "metadata": {},
   "source": [
    "# 2. Arrancar Airflow\n",
    "\n",
    "## 1.1. Base de datos (Postgres, SQLite, etc.)\n",
    "\n",
    "\n",
    "<div style=\"color:green\">\n",
    "** Más información en https://airflow.apache.org/docs/apache-airflow/stable/howto/set-up-database.html\n",
    "</div>\n",
    "\n",
    "##### PREPARAR EL POSTGRES\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "    \n",
    "    \n",
    "- CREATE DATABASE airflow_db;\n",
    "\n",
    "- CREATE USER airflow_user WITH PASSWORD 'XXX';\n",
    "    \n",
    "- GRANT ALL PRIVILEGES ON DATABASE airflow_db TO airflow_user;\n",
    "    \n",
    "- ALTER ROLE airflow_user SET search_path = public;    \n",
    "   \n",
    "    \n",
    "</div>\n",
    "\n",
    "##### INICIALIZAR POSTGRES\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "> airflow db init \n",
    "</div>\n",
    "\n",
    "\n",
    "##### CREAR USUARIO\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "> airflow users create --username admin --firstname admin --lastname admin --role Admin --email admin@admin.org \n",
    "</div>\n",
    "\n",
    "##### COMPROBAR USUARIO\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "> airflow users list \n",
    "</div>\n",
    "\n",
    "## 1.2. Webserver\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "> airflow webserver --port 8080\n",
    "</div>\n",
    "\n",
    "\n",
    "## 1.3. Scheduler\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "> airflow scheduler\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f5266c-867c-4f02-9b32-b5ac029d38eb",
   "metadata": {},
   "source": [
    "# 3. DAGS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c7c62-fa4e-4764-974c-f4208d515fac",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 01-check_file\n",
    "\n",
    "Comprobar que un fichero existe en la ruta dada. Para ello usamos un **BashOperator** que ejecuta un script de bash.\n",
    "\n",
    "Con este DAG aprenderemos:\n",
    "<div style=\"color:orange\">\n",
    "    \n",
    "    \n",
    "- Configurar Dags: parámetro, intervalos, programación...\n",
    "\n",
    "- Visualización de Dags en la web: Ver programación, estado del DAG, historial, logs...\n",
    "\n",
    "- Añadir markdown en DAG y las tareas (instance details).\n",
    "\n",
    "- BashOperator.\n",
    "    \n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf6d156-69ad-456b-b5c3-e8cec96521f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BashOperator(\n",
    "    task_id='check_file',\n",
    "    bash_command='sh ' + absolute_bash_file_path  + ' ' + absolute_file_path \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c5707-9bab-4bdd-b951-238126f76458",
   "metadata": {},
   "source": [
    "## 02-load-csv-to-GC\n",
    "\n",
    "Subir un fichero (en este caso csv) a un bucket de **Google Cloud Storage**.\n",
    "\n",
    "Con este DAG aprenderemos:\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "    \n",
    "    \n",
    "- PythonOperator.\n",
    "\n",
    "- Configuración de variables.\n",
    "\n",
    "- Organización de tareas de un DAG.\n",
    "\n",
    " </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363aab4e-f016-4610-bc88-12061e536a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "PythonOperator(\n",
    "    task_id='upload_csv_to_gcs',\n",
    "    python_callable=upload_csv_to_gcs,\n",
    "    #op_args=[absolute_file_path, bucket_name, destination_file_path]\n",
    "    op_kwargs={ \n",
    "        'file_path': absolute_file_path,\n",
    "        'bucket_name': bucket_name,\n",
    "        'destination_file_path': destination_file_path\n",
    "     }   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4ecbed-78e4-493c-bfaf-84ab5d657c71",
   "metadata": {},
   "source": [
    "## 03-load-data-to-big-query\n",
    "\n",
    "Añadir datos almacenados en **Google Cloud Storage** a **Big Query**.\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "\n",
    "- GCSToBigQueryOperator.\n",
    "\n",
    "- Configuración de conexiones.\n",
    "\n",
    " </div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a348e62-83e3-411c-8515-b7c83b5486ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCSToBigQueryOperator(\n",
    "    task_id='load_data_to_big_query',\n",
    "    bucket=bucket_name,\n",
    "    source_objects=[destination_file_path], # Todos los elementos del bucket\n",
    "    source_format='CSV', # Formato de los archivos a insertar\n",
    "    skip_leading_rows=1, # No considerar la primera fila como datos porque la primera fila son las cabeceras\n",
    "    field_delimiter=',', # Delimitador\n",
    "    destination_project_dataset_table='airflow-388217.external_data.enquestes', # id de la tabla + el nombre\n",
    "    create_disposition='CREATE_IF_NEEDED', # Crearla si no existe\n",
    "    write_disposition='WRITE_APPEND', # Añade a los datos existentes\n",
    "    bigquery_conn_id='google_cloud_default', # Valor por defecto\n",
    "    google_cloud_storage_conn_id='google_cloud_default' # Valor por defecto\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9acc82-ffb2-428f-853e-853098f3fe45",
   "metadata": {},
   "source": [
    " \n",
    "## 04-load-filtered-data-to-big-query\n",
    "\n",
    "Añadir datos desde una tabla de **Big Query** a otra filtrando a través de una query.\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "\n",
    "- BigQueryExecuteQueryOperator.\n",
    "\n",
    " </div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f09c98-2933-4562-8537-681e645957ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "BigQueryExecuteQueryOperator(\n",
    "    task_id='create_table_exiample',\n",
    "    sql=query,\n",
    "    destination_dataset_table=dataset_table_eixample,\n",
    "    write_disposition='WRITE_TRUNCATE', # Eliminar los datos antes de volver a escribir\n",
    "    create_disposition='CREATE_IF_NEEDED',\n",
    "    use_legacy_sql=False,\n",
    "    #bigquery_conn_id='google_cloud_default'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078e2eac-70cc-4a2d-9155-d1f1695610e8",
   "metadata": {},
   "source": [
    " \n",
    "\n",
    "## 05-remove-local-file\n",
    "\n",
    "Borrar csv de origen, un a vez se han ingestado en el bucket.\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "\n",
    "- Paralelización de tareas.\n",
    "\n",
    " </div> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f46391a-e1f8-48eb-b6a2-ff48ca41729e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "   \n",
    "    \n",
    " \n",
    " \n",
    "\n",
    " \n",
    " \n",
    " \n",
    "## 06-email-on-finish\n",
    "\n",
    "Enviar un correo\n",
    "\n",
    "<div style=\"color:orange\">\n",
    "\n",
    "- EmailOperator.\n",
    "\n",
    " </div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041b483-d82d-4ef4-8eac-faf90b2b7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EmailOperator(\n",
    "        task_id='send_email',\n",
    "        to=dest_email,\n",
    "        subject='La ejecución del dag ' + dag_args['dag_id'] +' correcta',\n",
    "        html_content=f'''<h3>ÉXITO EN LA EJECUCIÓN!!</h3> <p>La ejecución del dag {dag_args['dag_id']} ha acabado correctamente :)</p> ''',\n",
    "        dag=dag\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
